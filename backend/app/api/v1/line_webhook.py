# backend/app/api/v1/line_webhook.py
"""LINE Webhook API - AI æ™ºèƒ½ç‰ˆ"""

import os
import hashlib
import hmac
import base64
import json
from datetime import datetime, timedelta
from fastapi import APIRouter, Request, HTTPException, Depends
from sqlalchemy.orm import Session
import httpx
import google.generativeai as genai

from app.database import get_db
from app.services.realtime_weather import fetch_realtime_weather
from app.services.lunar import get_lunar_info
from app.models import DailyStatistics

router = APIRouter()

# è¨­å®š
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

# å³æ™‚å¤©æ°£ç«™é»
REALTIME_STATIONS = {
    "å°åŒ—": "466920", "è‡ºåŒ—": "466920", "æ–°åŒ—": "466881",
    "æ¡ƒåœ’": "467571", "æ–°ç«¹": "467571",
    "å°ä¸­": "467490", "è‡ºä¸­": "467490",
    "å˜‰ç¾©": "467480", "å°å—": "467410", "è‡ºå—": "467410",
    "é«˜é›„": "467441", "å±æ±": "467590",
    "èŠ±è“®": "466990", "å°æ±": "467660", "è‡ºæ±": "467660",
    "å®œè˜­": "467080", "åŸºéš†": "466940", "æ¾æ¹–": "467350",
}

# æ­·å²çµ±è¨ˆç«™é»
STATS_STATIONS = {
    "å°åŒ—": "466920", "è‡ºåŒ—": "466920", "æ–°åŒ—": "466920",
    "æ¡ƒåœ’": "467571", "æ–°ç«¹": "467571",
    "å°ä¸­": "467490", "è‡ºä¸­": "467490",
    "å˜‰ç¾©": "467480", "å°å—": "467410", "è‡ºå—": "467410",
    "é«˜é›„": "467440", "å±æ±": "467590",
    "èŠ±è“®": "466990", "å°æ±": "467660", "è‡ºæ±": "467660",
    "å®œè˜­": "466920", "åŸºéš†": "466940", "æ¾æ¹–": "467350",
}


def verify_signature(body: bytes, signature: str) -> bool:
    if not LINE_CHANNEL_SECRET:
        return True
    hash_value = hmac.new(LINE_CHANNEL_SECRET.encode(), body, hashlib.sha256).digest()
    return hmac.compare_digest(signature, base64.b64encode(hash_value).decode())


async def reply_line(reply_token: str, text: str) -> bool:
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                "https://api.line.me/v2/bot/message/reply",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
                },
                json={"replyToken": reply_token, "messages": [{"type": "text", "text": text}]}
            )
            return response.status_code == 200
    except Exception as e:
        print(f"LINE å›è¦†éŒ¯èª¤: {e}")
        return False


async def ai_process_query(user_message: str, db: Session) -> str:
    """ç”¨ AI è™•ç†æ‰€æœ‰ç”¨æˆ¶æŸ¥è©¢"""

    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel("gemini-2.0-flash")

    today = datetime.now()

    # ç¬¬ä¸€æ­¥ï¼šè®“ AI ç†è§£ç”¨æˆ¶æ„åœ–
    intent_prompt = f"""ä½ æ˜¯å¤©æ°£åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ¶è¨Šæ¯ï¼Œå›å‚³ JSONï¼ˆåªè¦ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ã€‚

ç”¨æˆ¶ï¼šã€Œ{user_message}ã€
ä»Šå¤©ï¼š{today.strftime('%Y-%m-%d')}ï¼ˆæ˜ŸæœŸ{['ä¸€','äºŒ','ä¸‰','å››','äº”','å…­','æ—¥'][today.weekday()]}ï¼‰

å›å‚³æ ¼å¼ï¼š
{{
  "intent": "realtime_weather" æˆ– "future_weather" æˆ– "recommend_dates" æˆ– "chat",
  "city": "åŸå¸‚å" æˆ– "å°åŒ—",
  "target_date": "MM-DD" æˆ– null,
  "days_from_today": æ•¸å­— æˆ– 0,
  "month": æœˆä»½æ•¸å­— æˆ– null,
  "preference": "sunny/rainy/cool" æˆ– null,
  "original_question": "ç”¨æˆ¶åŸå§‹å•é¡Œçš„é‡é»"
}}

è¦å‰‡ï¼š
- å•ç¾åœ¨/ä»Šå¤©å¤©æ°£ â†’ realtime_weather, days_from_today=0
- å•æ˜å¤©/å¾Œå¤©/Xå¤©å¾Œ/ä¸‹é€±X/ç‰¹å®šæ—¥æœŸ â†’ future_weather, ç®—å‡º days_from_today
- æ¨è–¦å¥½æ—¥å­/æ‰¾æ—¥æœŸ â†’ recommend_dates
- é–’èŠ/å…¶ä»– â†’ chat
- city åªèƒ½æ˜¯ï¼šå°åŒ—ã€æ–°åŒ—ã€æ¡ƒåœ’ã€æ–°ç«¹ã€å°ä¸­ã€å˜‰ç¾©ã€å°å—ã€é«˜é›„ã€å±æ±ã€èŠ±è“®ã€å°æ±ã€å®œè˜­ã€åŸºéš†ã€æ¾æ¹–"""

    try:
        response = model.generate_content(intent_prompt)
        response_text = response.text.strip()

        # æ¸…ç† JSON
        if "```" in response_text:
            response_text = response_text.split("```")[1]
            if response_text.startswith("json"):
                response_text = response_text[4:]
        response_text = response_text.strip()

        intent = json.loads(response_text)
        print(f"AI è§£æçµæœ: {intent}")

    except Exception as e:
        print(f"AI è§£æå¤±æ•—: {e}")
        # é™ç´šè™•ç†
        intent = {"intent": "realtime_weather", "city": "å°åŒ—", "days_from_today": 0}

    city = intent.get("city", "å°åŒ—")
    days_offset = intent.get("days_from_today", 0)
    intent_type = intent.get("intent", "realtime_weather")

    # ç¬¬äºŒæ­¥ï¼šæ ¹æ“šæ„åœ–å–å¾—è³‡æ–™
    if intent_type == "realtime_weather":
        return await get_realtime_weather_response(city, user_message, db, model)

    elif intent_type == "future_weather":
        return await get_future_weather_response(city, days_offset, user_message, db, model)

    elif intent_type == "recommend_dates":
        month = intent.get("month")
        preference = intent.get("preference", "sunny")
        return await get_recommend_response(city, month, preference, user_message, db, model)

    else:  # chat
        return await get_chat_response(user_message, model)


async def get_realtime_weather_response(city: str, question: str, db: Session, model) -> str:
    """å³æ™‚å¤©æ°£å›è¦†"""
    today = datetime.now()
    month_day = today.strftime("%m-%d")

    realtime_station = REALTIME_STATIONS.get(city, "466920")
    stats_station = STATS_STATIONS.get(city, "466920")

    realtime = await fetch_realtime_weather(realtime_station)
    stats = db.query(DailyStatistics).filter(
        DailyStatistics.station_id == stats_station,
        DailyStatistics.month_day == month_day
    ).first()

    lunar_info = get_lunar_info(today.date())
    lunar_date = lunar_info.get("lunar_date", {})

    if not realtime:
        return f"æŠ±æ­‰ï¼Œç„¡æ³•å–å¾— {city} çš„å³æ™‚å¤©æ°£è³‡æ–™ã€‚"

    # çµ„åˆè³‡æ–™çµ¦ AI
    weather_data = f"""
{city} å³æ™‚å¤©æ°£ï¼ˆ{realtime.obs_time.strftime('%H:%M') if realtime.obs_time else ''}ï¼‰ï¼š
- å¤©æ°£ï¼š{realtime.weather or 'æœªçŸ¥'}
- æ°£æº«ï¼š{realtime.temp}Â°C
- æœ€é«˜/æœ€ä½ï¼š{realtime.temp_max}Â°C / {realtime.temp_min}Â°C
- æ¿•åº¦ï¼š{realtime.humidity}%

æ­·å²çµ±è¨ˆï¼ˆ36å¹´ï¼‰ï¼š
- å¹³å‡æº«åº¦ï¼š{round(stats.temp_avg_mean, 1) if stats and stats.temp_avg_mean else 'N/A'}Â°C
- é™é›¨æ©Ÿç‡ï¼š{round(stats.precip_probability * 100) if stats and stats.precip_probability else 'N/A'}%

è¾²æ›†ï¼š{lunar_date.get('month_cn', '')}{lunar_date.get('day_cn', '')}
"""

    # è®“ AI ç”Ÿæˆå›è¦†
    reply_prompt = f"""æ ¹æ“šä»¥ä¸‹å¤©æ°£è³‡æ–™ï¼Œå›ç­”ç”¨æˆ¶å•é¡Œã€‚

{weather_data}

ç”¨æˆ¶å•ï¼šã€Œ{question}ã€

è¦æ±‚ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ¶çš„å•é¡Œ
- ç°¡æ½”æœ‰æº«åº¦ï¼Œ100å­—å…§
- å¯ä»¥çµ¦å‡ºå»ºè­°ï¼ˆå¦‚ï¼šå¸¶å‚˜ã€ç©¿å¤–å¥—ï¼‰
- é©åº¦ç”¨ emoji"""

    response = model.generate_content(reply_prompt)
    return response.text.strip()


async def get_future_weather_response(city: str, days_offset: int, question: str, db: Session, model) -> str:
    """æœªä¾†å¤©æ°£å›è¦†ï¼ˆç”¨æ­·å²çµ±è¨ˆï¼‰"""
    target_date = datetime.now() + timedelta(days=days_offset)
    month_day = target_date.strftime("%m-%d")

    stats_station = STATS_STATIONS.get(city, "466920")
    stats = db.query(DailyStatistics).filter(
        DailyStatistics.station_id == stats_station,
        DailyStatistics.month_day == month_day
    ).first()

    if not stats:
        return f"æŠ±æ­‰ï¼Œæ‰¾ä¸åˆ° {city} åœ¨ {month_day} çš„æ­·å²è³‡æ–™ã€‚"

    weather_data = f"""
{city} {target_date.strftime('%m/%d')}ï¼ˆ{days_offset}å¤©å¾Œï¼‰æ­·å²çµ±è¨ˆï¼ˆ36å¹´è³‡æ–™ï¼‰ï¼š
- å¹³å‡æº«åº¦ï¼š{round(stats.temp_avg_mean, 1) if stats.temp_avg_mean else 'N/A'}Â°C
- å¹³å‡æœ€é«˜æº«ï¼š{round(stats.temp_max_mean, 1) if stats.temp_max_mean else 'N/A'}Â°C
- å¹³å‡æœ€ä½æº«ï¼š{round(stats.temp_min_mean, 1) if stats.temp_min_mean else 'N/A'}Â°C
- é™é›¨æ©Ÿç‡ï¼š{round(stats.precip_probability * 100) if stats.precip_probability else 'N/A'}%
"""

    reply_prompt = f"""æ ¹æ“šæ­·å²çµ±è¨ˆè³‡æ–™ï¼Œå›ç­”ç”¨æˆ¶é—œæ–¼æœªä¾†å¤©æ°£çš„å•é¡Œã€‚

{weather_data}

ç”¨æˆ¶å•ï¼šã€Œ{question}ã€

è¦æ±‚ï¼š
- èªªæ˜é€™æ˜¯æ ¹æ“š 36 å¹´æ­·å²è³‡æ–™çš„çµ±è¨ˆé ä¼°
- çµ¦å‡ºå¯¦ç”¨å»ºè­°
- ç°¡æ½”ï¼Œ100å­—å…§
- é©åº¦ç”¨ emoji"""

    response = model.generate_content(reply_prompt)
    return response.text.strip()


async def get_recommend_response(city: str, month: int, preference: str, question: str, db: Session, model) -> str:
    """æ—¥æœŸæ¨è–¦å›è¦†"""
    stats_station = STATS_STATIONS.get(city, "466920")

    if month:
        stats_list = db.query(DailyStatistics).filter(
            DailyStatistics.station_id == stats_station,
            DailyStatistics.month_day.like(f"{month:02d}-%")
        ).all()
    else:
        # æœªä¾† 3 å€‹æœˆ
        current_month = datetime.now().month
        months = [(current_month + i - 1) % 12 + 1 for i in range(3)]
        stats_list = db.query(DailyStatistics).filter(
            DailyStatistics.station_id == stats_station
        ).all()
        stats_list = [s for s in stats_list if int(s.month_day.split("-")[0]) in months]

    if not stats_list:
        return f"æŠ±æ­‰ï¼Œæ‰¾ä¸åˆ° {city} çš„æ­·å²è³‡æ–™ã€‚"

    # æŒ‰åå¥½æ’åº
    if preference == "sunny" or preference == "dry":
        sorted_stats = sorted(stats_list, key=lambda s: s.precip_probability or 1)
    elif preference == "cool":
        sorted_stats = sorted(stats_list, key=lambda s: abs((s.temp_avg_mean or 25) - 23))
    else:
        sorted_stats = sorted(stats_list, key=lambda s: s.precip_probability or 1)

    top5 = sorted_stats[:5]
    dates_info = "\n".join([
        f"- {s.month_day}ï¼šå¹³å‡ {round(s.temp_avg_mean, 1) if s.temp_avg_mean else 'N/A'}Â°Cï¼Œé™é›¨æ©Ÿç‡ {round(s.precip_probability * 100) if s.precip_probability else 'N/A'}%"
        for s in top5
    ])

    reply_prompt = f"""æ ¹æ“š {city} 36å¹´æ­·å²è³‡æ–™ï¼Œæ¨è–¦æ—¥æœŸå¦‚ä¸‹ï¼š

{dates_info}

ç”¨æˆ¶å•ï¼šã€Œ{question}ã€

è¦æ±‚ï¼š
- èªªæ˜æ¨è–¦åŸå› 
- ç°¡æ½”å¯¦ç”¨ï¼Œ100å­—å…§
- é©åº¦ç”¨ emoji"""

    response = model.generate_content(reply_prompt)
    return response.text.strip()


async def get_chat_response(question: str, model) -> str:
    """é–’èŠå›è¦†"""
    prompt = f"""ä½ æ˜¯ã€Œå¥½æ—¥å­ã€å¤©æ°£æ©Ÿå™¨äººï¼Œè¦ªåˆ‡å‹å–„ã€‚

ç”¨æˆ¶èªªï¼šã€Œ{question}ã€

å›ç­”è¦æ±‚ï¼š
- å¦‚æœæ˜¯æ‰“æ‹›å‘¼ï¼Œå‹å–„å›æ‡‰ä¸¦ä»‹ç´¹è‡ªå·±èƒ½æŸ¥å¤©æ°£
- å¦‚æœæ˜¯å•åŠŸèƒ½ï¼Œèªªæ˜å¯ä»¥æŸ¥å³æ™‚å¤©æ°£ã€æœªä¾†å¤©æ°£é ä¼°ã€æ¨è–¦å¥½æ—¥å­
- ç°¡æ½”ï¼Œ50å­—å…§
- é©åº¦ç”¨ emoji"""

    response = model.generate_content(prompt)
    return response.text.strip()


@router.post("/webhook")
async def line_webhook(request: Request, db: Session = Depends(get_db)):
    body = await request.body()
    signature = request.headers.get("X-Line-Signature", "")

    if not verify_signature(body, signature):
        raise HTTPException(status_code=400, detail="Invalid signature")

    try:
        data = await request.json()
    except:
        raise HTTPException(status_code=400, detail="Invalid JSON")

    for event in data.get("events", []):
        reply_token = event.get("replyToken")
        if not reply_token:
            continue

        if event.get("type") == "message":
            msg = event.get("message", {})
            if msg.get("type") == "text":
                user_text = msg.get("text", "")

                try:
                    reply = await ai_process_query(user_text, db)
                except Exception as e:
                    print(f"è™•ç†å¤±æ•—: {e}")
                    reply = "æŠ±æ­‰ï¼Œç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

                await reply_line(reply_token, reply)

        elif event.get("type") == "follow":
            await reply_line(reply_token, "ğŸ‘‹ å—¨ï¼æˆ‘æ˜¯å¥½æ—¥å­å¤©æ°£æ©Ÿå™¨äºº\n\nç›´æ¥å•æˆ‘å¤©æ°£å•é¡Œå§ï¼\nä¾‹å¦‚ï¼šå°åŒ—å¤©æ°£ã€æ˜å¤©æœƒä¸‹é›¨å—ã€æ¨è–¦äº”æœˆå¥½æ—¥å­")

    return {"status": "ok"}


@router.get("/webhook")
async def verify_webhook():
    return {"status": "ok"}

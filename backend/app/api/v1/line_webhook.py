# backend/app/api/v1/line_webhook.py
"""LINE Webhook API

è™•ç† LINE Bot æ¥æ”¶çš„è¨Šæ¯ä¸¦å›è¦†å¤©æ°£è³‡è¨Šã€‚
"""

import os
import hashlib
import hmac
import base64
from datetime import datetime
from fastapi import APIRouter, Request, HTTPException, Depends
from sqlalchemy.orm import Session
import httpx

from app.database import get_db
from app.services.realtime_weather import fetch_realtime_weather
from app.services.lunar import get_lunar_info
from app.services.solar_term import get_current_solar_term
from app.models import DailyStatistics, Station
from app.services.decade_stats import get_extreme_records
from app.services.ai_engine import generate_daily_insight

router = APIRouter()

# LINE è¨­å®š
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_REPLY_URL = "https://api.line.me/v2/bot/message/reply"

# ç«™é»å°æ‡‰ï¼ˆåªä½¿ç”¨æœ‰ 36 å¹´æ­·å²è³‡æ–™çš„ç«™é»ï¼‰
STATION_MAPPING = {
    "å°åŒ—": "466920",
    "è‡ºåŒ—": "466920",
    "æ–°åŒ—": "466920",
    "æ¿æ©‹": "466920",  # ä½¿ç”¨å°åŒ—ç«™
    "æ¡ƒåœ’": "467571",  # ä½¿ç”¨æ–°ç«¹ç«™ï¼ˆæœ€è¿‘ï¼‰
    "æ–°ç«¹": "467571",
    "å°ä¸­": "467490",
    "è‡ºä¸­": "467490",
    "å½°åŒ–": "467490",  # ä½¿ç”¨å°ä¸­ç«™
    "å—æŠ•": "467650",  # æ—¥æœˆæ½­
    "å˜‰ç¾©": "467480",
    "é˜¿é‡Œå±±": "467530",
    "å°å—": "467410",
    "è‡ºå—": "467410",
    "é«˜é›„": "467440",
    "å±æ±": "467590",  # æ†æ˜¥
    "æ†æ˜¥": "467590",
    "èŠ±è“®": "466990",
    "å°æ±": "467660",
    "è‡ºæ±": "467660",
    "å®œè˜­": "466920",  # ä½¿ç”¨å°åŒ—ç«™ï¼ˆæœ€è¿‘ï¼‰
    "åŸºéš†": "466940",
    "æ¾æ¹–": "467350",
}


def verify_signature(body: bytes, signature: str) -> bool:
    """é©—è­‰ LINE ç°½å"""
    if not LINE_CHANNEL_SECRET:
        return True  # é–‹ç™¼ç’°å¢ƒå¯è·³éé©—è­‰

    hash_value = hmac.new(
        LINE_CHANNEL_SECRET.encode('utf-8'),
        body,
        hashlib.sha256
    ).digest()
    expected_signature = base64.b64encode(hash_value).decode('utf-8')
    return hmac.compare_digest(signature, expected_signature)


async def reply_message(reply_token: str, messages: list[dict]) -> bool:
    """å›è¦† LINE è¨Šæ¯"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
    }

    payload = {
        "replyToken": reply_token,
        "messages": messages,
    }

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(LINE_REPLY_URL, headers=headers, json=payload)
            return response.status_code == 200
    except Exception as e:
        print(f"LINE å›è¦†éŒ¯èª¤: {e}")
        return False


async def parse_user_query_with_ai(text: str) -> dict:
    """ä½¿ç”¨ AI è§£æç”¨æˆ¶æŸ¥è©¢æ„åœ–

    Returns:
        dict: {"type": "weather|recommend|help|chat", ...}
    """
    import google.generativeai as genai
    from app.config import settings

    text = text.strip()

    # å¹«åŠ©æŒ‡ä»¤ï¼ˆå¿«é€Ÿè™•ç†ï¼‰
    if text.lower() in ["help", "å¹«åŠ©", "èªªæ˜", "?", "ï¼Ÿ", "æŒ‡ä»¤"]:
        return {"type": "help", "city": None, "original_query": text}

    # ä½¿ç”¨ AI è§£ææ„åœ–
    try:
        genai.configure(api_key=settings.gemini_api_key)
        model = genai.GenerativeModel("gemini-2.0-flash")

        prompt = f"""ä½ æ˜¯ä¸€å€‹å¤©æ°£æŸ¥è©¢åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ¶çš„è¨Šæ¯ï¼Œåˆ¤æ–·ä»–å€‘æƒ³è¦ä»€éº¼ã€‚

ç”¨æˆ¶è¨Šæ¯ï¼šã€Œ{text}ã€

è«‹ç”¨ JSON æ ¼å¼å›ç­”ï¼ˆåªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "intent": "weather" æˆ– "recommend" æˆ– "chat" æˆ– "help",
  "city": "åŸå¸‚å" æˆ– null,
  "month": æœˆä»½æ•¸å­—(1-12) æˆ– null,
  "preference": "sunny" æˆ– "cool" æˆ– "dry" æˆ– null,
  "days": é€£çºŒå¤©æ•¸ æˆ– null,
  "needs_ai_response": true æˆ– false
}}

è¦å‰‡ï¼š
- "weather"ï¼šæŸ¥è©¢å³æ™‚å¤©æ°£ã€ä»Šå¤©æœƒä¸æœƒä¸‹é›¨ç­‰
- "recommend"ï¼šæ¨è–¦å¥½æ—¥å­ã€æ‰¾ç‰¹å®šæ¢ä»¶çš„æ—¥æœŸï¼ˆå¦‚ï¼šé€£çºŒæ™´å¤©ã€é©åˆå‡ºéŠçš„æ—¥å­ã€å¹¾æœˆå¹¾è™Ÿé©åˆè¾¦æ´»å‹•ï¼‰
- "chat"ï¼šé–’èŠã€æ‰“æ‹›å‘¼ã€éå¤©æ°£å•é¡Œ
- "help"ï¼šè©¢å•åŠŸèƒ½ã€æ€éº¼ä½¿ç”¨

- city åªèƒ½æ˜¯ï¼šå°åŒ—ã€æ–°åŒ—ã€æ¡ƒåœ’ã€æ–°ç«¹ã€å°ä¸­ã€å½°åŒ–ã€å—æŠ•ã€å˜‰ç¾©ã€å°å—ã€é«˜é›„ã€å±æ±ã€èŠ±è“®ã€å°æ±ã€å®œè˜­ã€åŸºéš†ã€æ¾æ¹–
- å¦‚æœæ²’æåˆ°åŸå¸‚ï¼Œcity è¨­ç‚º nullï¼ˆæœƒç”¨å°åŒ—ï¼‰
- preferenceï¼šæ™´å¤©/å‡ºéŠ/æˆ¶å¤–=sunnyï¼Œæ¶¼çˆ½/èˆ’é©=coolï¼Œä¹¾ç‡¥/ä¸ä¸‹é›¨=dry
- daysï¼šå¦‚æœç”¨æˆ¶èªªã€Œé€£çºŒä¸‰å¤©ã€å°±æ˜¯ 3"""

        response = model.generate_content(prompt)
        response_text = response.text.strip()

        # è§£æ JSON
        import json
        if response_text.startswith("```"):
            response_text = response_text.split("```")[1]
            if response_text.startswith("json"):
                response_text = response_text[4:]
        response_text = response_text.strip()

        result = json.loads(response_text)

        intent = result.get("intent", "chat")
        city = result.get("city") or "å°åŒ—"
        month = result.get("month")
        preference = result.get("preference") or "sunny"
        days = result.get("days")
        needs_ai = result.get("needs_ai_response", False)

        # ç¢ºèªåŸå¸‚æœ‰å°æ‡‰çš„ç«™é»
        station_id = STATION_MAPPING.get(city, "466920")

        if intent == "weather":
            return {
                "type": "weather",
                "city": city,
                "station_id": station_id,
                "original_query": text,
                "needs_ai": needs_ai
            }
        elif intent == "recommend":
            return {
                "type": "recommend",
                "city": city,
                "station_id": station_id,
                "month": month,
                "preference": preference,
                "days": days,
                "original_query": text
            }
        elif intent == "help":
            return {"type": "help", "city": None, "original_query": text}
        else:
            return {"type": "chat", "city": None, "original_query": text, "needs_ai": True}

    except Exception as e:
        print(f"AI è§£æå¤±æ•—: {e}")
        return parse_user_query_fallback(text)


def parse_user_query_fallback(text: str) -> dict:
    """å‚™ç”¨ï¼šé—œéµå­—åŒ¹é…ï¼ˆç•¶ AI å¤±æ•—æ™‚ï¼‰"""
    text_lower = text.strip().lower()

    for city, station_id in STATION_MAPPING.items():
        if city in text_lower:
            return {"type": "weather", "city": city, "station_id": station_id, "original_query": text}

    if any(kw in text_lower for kw in ["å¤©æ°£", "æ°£æº«", "æº«åº¦", "ä¸‹é›¨", "å‡ºé–€", "ç†±", "å†·"]):
        return {"type": "weather", "city": "å°åŒ—", "station_id": "466920", "original_query": text}

    return {"type": "chat", "city": None, "original_query": text, "needs_ai": True}


async def generate_ai_chat_response(user_query: str, weather_context: dict = None) -> str:
    """ä½¿ç”¨ AI ç”Ÿæˆæ™ºæ…§å°è©±å›è¦†"""
    import google.generativeai as genai
    from app.config import settings

    try:
        genai.configure(api_key=settings.gemini_api_key)
        model = genai.GenerativeModel("gemini-2.0-flash")

        context = """ä½ æ˜¯ã€Œå¥½æ—¥å­ã€å¤©æ°£æ©Ÿå™¨äººï¼Œä¸€å€‹è¦ªåˆ‡ã€å°ˆæ¥­çš„å°ç£å¤©æ°£åŠ©æ‰‹ã€‚

ä½ çš„ç‰¹è‰²ï¼š
1. çµåˆ 36 å¹´æ­·å²æ°£è±¡æ•¸æ“šï¼Œèƒ½å‘Šè¨´ç”¨æˆ¶ä»Šå¤©è·Ÿå¾€å¹´æ¯”è¼ƒå¦‚ä½•
2. èåˆè¾²æ›†ã€ç¯€æ°£ç­‰å‚³çµ±æ™ºæ…§
3. å›ç­”è¦ç°¡æ½”ã€æœ‰æº«åº¦ã€å¯¦ç”¨

å›ç­”é¢¨æ ¼ï¼š
- ç”¨ç¹é«”ä¸­æ–‡
- é©åº¦ä½¿ç”¨ emoji
- åƒæœ‹å‹èŠå¤©ä¸€æ¨£è‡ªç„¶
- æ§åˆ¶åœ¨ 200 å­—ä»¥å…§"""

        if weather_context:
            context += f"""

ç›®å‰å¤©æ°£è³‡æ–™ï¼š
- åœ°é»ï¼š{weather_context.get('city', 'å°åŒ—')}
- å³æ™‚å¤©æ°£ï¼š{weather_context.get('weather', 'æœªçŸ¥')}
- æ°£æº«ï¼š{weather_context.get('temp', 'N/A')}Â°C
- æ­·å²å¹³å‡ï¼š{weather_context.get('hist_avg', 'N/A')}Â°C
- ä»Šæ—¥å·®ç•°ï¼š{weather_context.get('diff', 'N/A')}Â°C
- é™é›¨æ©Ÿç‡ï¼š{weather_context.get('rain_prob', 'N/A')}%
- è¾²æ›†ï¼š{weather_context.get('lunar', '')}"""

        prompt = f"{context}\n\nç”¨æˆ¶å•ï¼šã€Œ{user_query}ã€\n\nè«‹å›ç­”ï¼š"

        response = model.generate_content(prompt)
        return response.text.strip()

    except Exception as e:
        print(f"AI å°è©±å¤±æ•—: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨æœ‰é»å¿™ï¼Œè«‹ç¨å¾Œå†å•æˆ‘å¤©æ°£å•é¡Œï¼"


async def generate_weather_reply(station_id: str, city: str, db: Session, user_query: str = None, needs_ai: bool = False) -> str:
    """ç”Ÿæˆå¤©æ°£å›è¦†è¨Šæ¯"""
    today = datetime.now()
    month_day = today.strftime("%m-%d")

    # å–å¾—å³æ™‚å¤©æ°£
    realtime = await fetch_realtime_weather(station_id)

    # å–å¾—æ­·å²çµ±è¨ˆ
    stats = db.query(DailyStatistics).filter(
        DailyStatistics.station_id == station_id,
        DailyStatistics.month_day == month_day
    ).first()

    # å–å¾—è¾²æ›†
    lunar_info = get_lunar_info(today.date())
    lunar_date = lunar_info.get("lunar_date", {})

    # å–å¾—æ¥µå€¼
    extreme_records = get_extreme_records(db, station_id, month_day)

    if realtime:
        temp = realtime.temp
        weather = realtime.weather or "æœªçŸ¥"
        humidity = realtime.humidity
        precipitation = realtime.precipitation or 0
        temp_max = realtime.temp_max
        temp_min = realtime.temp_min
        obs_time = realtime.obs_time.strftime("%H:%M") if realtime.obs_time else ""
    else:
        return f"æŠ±æ­‰ï¼Œç„¡æ³•å–å¾— {city} çš„å³æ™‚å¤©æ°£è³‡æ–™ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"

    # æ­·å²æ¯”è¼ƒ
    hist_avg = round(stats.temp_avg_mean, 1) if stats and stats.temp_avg_mean else None
    if hist_avg and temp:
        diff = round(temp - hist_avg, 1)
        diff_str = f"+{diff}" if diff > 0 else str(diff)
    else:
        diff_str = "N/A"
        diff = None

    # é™é›¨æ©Ÿç‡
    if stats and stats.precip_probability is not None:
        rain_prob = round(stats.precip_probability * 100)
    else:
        rain_prob = None

    # è¾²æ›†
    lunar_str = f"{lunar_date.get('month_cn', '')}{lunar_date.get('day_cn', '')}"

    # å¦‚æœéœ€è¦ AI æ™ºæ…§å›è¦†ï¼ˆç”¨æˆ¶å•äº†ç‰¹å®šå•é¡Œï¼‰
    if needs_ai and user_query:
        weather_context = {
            "city": city,
            "weather": weather,
            "temp": temp,
            "temp_max": temp_max,
            "temp_min": temp_min,
            "humidity": humidity,
            "hist_avg": hist_avg,
            "diff": diff_str,
            "rain_prob": rain_prob,
            "lunar": lunar_str,
        }
        return await generate_ai_chat_response(user_query, weather_context)

    # æ¨™æº–å¤©æ°£å ±å‘Š
    if rain_prob is not None:
        if rain_prob >= 60:
            rain_advice = "â˜” é«˜æ©Ÿç‡é™é›¨ï¼Œè¨˜å¾—å¸¶å‚˜ï¼"
        elif rain_prob >= 30:
            rain_advice = "ğŸŒ‚ å¯èƒ½ä¸‹é›¨ï¼Œå»ºè­°å‚™å‚˜"
        else:
            rain_advice = "â˜€ï¸ é™é›¨æ©Ÿç‡ä½"
    else:
        rain_advice = ""

    message = f"""ğŸŒ¤ {city}å¤©æ°£ï¼ˆ{obs_time}ï¼‰

â€¢ å¤©æ°£ï¼š{weather}
â€¢ æ°£æº«ï¼š{temp}Â°C
â€¢ é«˜ä½æº«ï¼š{temp_min}Â°C ~ {temp_max}Â°C
â€¢ æ¿•åº¦ï¼š{round(humidity) if humidity else 'N/A'}%

ğŸ“Š æ­·å²æ¯”è¼ƒï¼ˆ36å¹´ï¼‰
â€¢ å¹³å‡ï¼š{hist_avg if hist_avg else 'N/A'}Â°C
â€¢ ä»Šæ—¥å·®ç•°ï¼š{diff_str}Â°C

ğŸŒ§ é™é›¨
â€¢ ç´¯ç©é›¨é‡ï¼š{precipitation}mm
â€¢ æ­·å²æ©Ÿç‡ï¼š{rain_prob if rain_prob else 'N/A'}%
{rain_advice}

ğŸ“… {today.strftime('%m/%d')}ï¼ˆè¾²æ›†{lunar_str}ï¼‰"""

    return message


async def generate_recommend_reply(query: dict, db: Session) -> str:
    """ç”Ÿæˆæ—¥æœŸæ¨è–¦å›è¦†"""
    import google.generativeai as genai
    from app.config import settings

    station_id = query.get("station_id", "466920")
    city = query.get("city", "å°åŒ—")
    month = query.get("month")
    preference = query.get("preference", "sunny")
    days = query.get("days")
    original_query = query.get("original_query", "")

    # å–å¾—æ¨è–¦æ—¥æœŸ
    from app.models import DailyStatistics

    # æŸ¥è©¢è©²æœˆä»½çš„çµ±è¨ˆè³‡æ–™
    if month:
        month_prefix = f"{month:02d}-"
        stats_list = db.query(DailyStatistics).filter(
            DailyStatistics.station_id == station_id,
            DailyStatistics.month_day.like(f"{month_prefix}%")
        ).all()
    else:
        # æœªæŒ‡å®šæœˆä»½ï¼ŒæŸ¥è©¢æœªä¾† 3 å€‹æœˆ
        from datetime import datetime
        current_month = datetime.now().month
        months = [(current_month + i - 1) % 12 + 1 for i in range(3)]
        stats_list = db.query(DailyStatistics).filter(
            DailyStatistics.station_id == station_id
        ).all()
        stats_list = [s for s in stats_list if int(s.month_day.split("-")[0]) in months]

    if not stats_list:
        return f"æŠ±æ­‰ï¼Œæ‰¾ä¸åˆ° {city} çš„æ­·å²è³‡æ–™ä¾†æ¨è–¦æ—¥æœŸã€‚"

    # æ ¹æ“šåå¥½æ’åº
    def score_day(stat):
        score = 0
        if preference == "sunny":
            # æ™´å¤©åå¥½ï¼šä½é™é›¨æ©Ÿç‡
            if stat.precip_probability:
                score -= stat.precip_probability * 100
        elif preference == "cool":
            # æ¶¼çˆ½åå¥½ï¼šæº«åº¦æ¥è¿‘ 22-25 åº¦
            if stat.temp_avg_mean:
                score -= abs(stat.temp_avg_mean - 23) * 5
        elif preference == "dry":
            # ä¹¾ç‡¥åå¥½ï¼šä½é™é›¨æ©Ÿç‡
            if stat.precip_probability:
                score -= stat.precip_probability * 100
        return score

    sorted_stats = sorted(stats_list, key=score_day, reverse=True)

    # å¦‚æœè¦é€£çºŒå¤©æ•¸
    if days and days > 1:
        best_sequences = []
        for i in range(len(sorted_stats) - days + 1):
            # æª¢æŸ¥æ˜¯å¦é€£çºŒ
            seq = sorted_stats[i:i+days]
            # ç°¡åŒ–ï¼šåªå–å‰å¹¾åçµ„åˆ
            avg_score = sum(score_day(s) for s in seq) / days
            best_sequences.append((seq, avg_score))
        best_sequences.sort(key=lambda x: x[1], reverse=True)
        top_dates = best_sequences[0][0] if best_sequences else sorted_stats[:days]
    else:
        top_dates = sorted_stats[:5]

    # ä½¿ç”¨ AI ç”Ÿæˆå‹å–„å›è¦†
    try:
        genai.configure(api_key=settings.gemini_api_key)
        model = genai.GenerativeModel("gemini-2.0-flash")

        dates_info = []
        for stat in top_dates[:5]:
            rain_prob = round(stat.precip_probability * 100) if stat.precip_probability else "N/A"
            temp = round(stat.temp_avg_mean, 1) if stat.temp_avg_mean else "N/A"
            dates_info.append(f"- {stat.month_day}ï¼šå¹³å‡ {temp}Â°Cï¼Œé™é›¨æ©Ÿç‡ {rain_prob}%")

        dates_str = "\n".join(dates_info)

        prompt = f"""ç”¨æˆ¶å•ï¼šã€Œ{original_query}ã€

æ ¹æ“š {city} 36å¹´æ­·å²è³‡æ–™ï¼Œæ¨è–¦çš„æ—¥æœŸå¦‚ä¸‹ï¼š
{dates_str}

è«‹ç”¨è¦ªåˆ‡çš„æ–¹å¼å›ç­”ç”¨æˆ¶ï¼Œèªªæ˜æ¨è–¦åŸå› ã€‚
- ç°¡æ½”æœ‰åŠ›ï¼Œä¸è¶…é 150 å­—
- é©åº¦ç”¨ emoji
- å¦‚æœç”¨æˆ¶å•é€£çºŒå¤©æ•¸ï¼Œèªªæ˜é€™å¹¾å¤©çš„ç‰¹é»"""

        response = model.generate_content(prompt)
        return response.text.strip()

    except Exception as e:
        print(f"AI æ¨è–¦å›è¦†å¤±æ•—: {e}")
        # é™ç´šå›è¦†
        dates_str = ", ".join([s.month_day for s in top_dates[:5]])
        return f"ğŸŒ¤ æ ¹æ“š {city} 36å¹´æ­·å²ï¼Œæ¨è–¦æ—¥æœŸï¼š{dates_str}\né€™äº›æ—¥å­å¤©æ°£è¼ƒç©©å®šï¼"


def get_help_message() -> str:
    """å›å‚³èªªæ˜è¨Šæ¯"""
    return """ğŸŒ¤ å¥½æ—¥å­å¤©æ°£æ©Ÿå™¨äºº

ğŸ“ æŸ¥è©¢å¤©æ°£ï¼š
ç›´æ¥è¼¸å…¥åŸå¸‚åç¨±å³å¯ï¼
ä¾‹å¦‚ï¼šå°åŒ—ã€é«˜é›„ã€èŠ±è“®

æ”¯æ´åŸå¸‚ï¼š
å°åŒ—ã€æ¿æ©‹ã€æ¡ƒåœ’ã€æ–°ç«¹
å°ä¸­ã€å½°åŒ–ã€å˜‰ç¾©
å°å—ã€é«˜é›„ã€å±æ±
èŠ±è“®ã€å°æ±ã€å®œè˜­

ğŸ’¡ å°æŠ€å·§ï¼š
â€¢ è¼¸å…¥ã€Œå¤©æ°£ã€æŸ¥å°åŒ—
â€¢ è¼¸å…¥ã€Œé«˜é›„å¤©æ°£ã€æŸ¥é«˜é›„
â€¢ è¼¸å…¥ã€Œæœƒä¸‹é›¨å—ã€æŸ¥å°åŒ—é™é›¨

ğŸ”— å®Œæ•´åŠŸèƒ½ï¼š
https://auspicious-zeta.vercel.app"""


@router.post("/webhook")
async def line_webhook(request: Request, db: Session = Depends(get_db)):
    """LINE Webhook ç«¯é»"""
    # å–å¾—è«‹æ±‚å…§å®¹
    body = await request.body()
    signature = request.headers.get("X-Line-Signature", "")

    # é©—è­‰ç°½å
    if not verify_signature(body, signature):
        raise HTTPException(status_code=400, detail="Invalid signature")

    # è§£æäº‹ä»¶
    try:
        data = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid JSON")

    events = data.get("events", [])

    for event in events:
        event_type = event.get("type")
        reply_token = event.get("replyToken")

        if not reply_token:
            continue

        # è™•ç†è¨Šæ¯äº‹ä»¶
        if event_type == "message":
            message = event.get("message", {})
            message_type = message.get("type")

            if message_type == "text":
                user_text = message.get("text", "")

                # ä½¿ç”¨ AI è§£ææ„åœ–
                query = await parse_user_query_with_ai(user_text)

                if query["type"] == "help":
                    reply_text = get_help_message()
                elif query["type"] == "weather":
                    reply_text = await generate_weather_reply(
                        query["station_id"],
                        query["city"],
                        db,
                        user_query=query.get("original_query"),
                        needs_ai=query.get("needs_ai", False)
                    )
                elif query["type"] == "recommend":
                    reply_text = await generate_recommend_reply(query, db)
                elif query["type"] == "chat":
                    # ç´”èŠå¤©ï¼Œç”¨ AI å›è¦†
                    reply_text = await generate_ai_chat_response(user_text)
                else:
                    reply_text = await generate_ai_chat_response(user_text)

                await reply_message(reply_token, [{"type": "text", "text": reply_text}])

        # è™•ç†åŠ å¥½å‹äº‹ä»¶
        elif event_type == "follow":
            welcome = """ğŸ‘‹ æ­¡è¿ä½¿ç”¨å¥½æ—¥å­å¤©æ°£æ©Ÿå™¨äººï¼

ç›´æ¥è¼¸å…¥åŸå¸‚åç¨±å³å¯æŸ¥è©¢å¤©æ°£
ä¾‹å¦‚ï¼šå°åŒ—ã€é«˜é›„ã€èŠ±è“®

è¼¸å…¥ã€Œå¹«åŠ©ã€æŸ¥çœ‹å®Œæ•´èªªæ˜ ğŸŒ¤"""
            await reply_message(reply_token, [{"type": "text", "text": welcome}])

    return {"status": "ok"}


@router.get("/webhook")
async def verify_webhook():
    """LINE Webhook é©—è­‰ç«¯é»ï¼ˆGET è«‹æ±‚ï¼‰"""
    return {"status": "ok", "message": "Webhook is ready"}

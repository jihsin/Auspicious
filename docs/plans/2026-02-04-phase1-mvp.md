# Phase 1 MVP 實作計畫

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** 建立「好日子」App 的 Phase 1 MVP — 台北站歷史天氣統計查詢 Web 應用

**Architecture:**
- 後端：FastAPI + SQLite（MVP 階段）+ 預計算統計快照
- 前端：Next.js 14 + Tailwind CSS + shadcn/ui + Recharts
- 數據：從 GitHub Raingel/historical_weather 下載台北站 30+ 年歷史數據
- 部署：Docker + Google Cloud Run

**Tech Stack:**
- Python 3.11+, FastAPI, SQLAlchemy, Pandas, Poetry
- Node.js 20, Next.js 14, React 18, TypeScript, pnpm
- SQLite (MVP), Docker, GitHub Actions

---

## Sprint 0: 專案初始化

### Task 0.1: 建立 Monorepo 目錄結構

**Files:**
- Create: `backend/` directory
- Create: `frontend/` directory
- Create: `data-pipeline/` directory
- Create: `.gitignore`

**Step 1: 建立目錄結構**

```bash
mkdir -p backend/app/{api/v1,models,schemas,analytics}
mkdir -p backend/tests
mkdir -p frontend/src/{app,components,lib,hooks,store}
mkdir -p data-pipeline
mkdir -p data/raw data/processed
```

**Step 2: 建立 .gitignore**

```gitignore
# Python
__pycache__/
*.py[cod]
.venv/
*.egg-info/
dist/
.pytest_cache/
.mypy_cache/
.ruff_cache/

# Node
node_modules/
.next/
out/

# Data
data/raw/
data/processed/
*.csv
*.db
*.sqlite

# Environment
.env
.env.local
.env.*.local

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db
```

**Step 3: Commit**

```bash
git add -A
git commit -m "chore: initialize monorepo directory structure"
```

---

### Task 0.2: 設定 Python 後端環境

**Files:**
- Create: `backend/pyproject.toml`
- Create: `backend/app/__init__.py`
- Create: `backend/app/main.py`

**Step 1: 建立 pyproject.toml**

```toml
[tool.poetry]
name = "auspicious-backend"
version = "0.1.0"
description = "好日子 App 後端服務"
authors = ["Tom Wang"]
readme = "README.md"
packages = [{include = "app"}]

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.109.0"
uvicorn = {extras = ["standard"], version = "^0.27.0"}
sqlalchemy = "^2.0.25"
pydantic = "^2.6.0"
pydantic-settings = "^2.1.0"
pandas = "^2.2.0"
numpy = "^1.26.0"
httpx = "^0.26.0"
python-dateutil = "^2.8.2"

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
pytest-asyncio = "^0.23.0"
pytest-cov = "^4.1.0"
ruff = "^0.2.0"
mypy = "^1.8.0"
pre-commit = "^3.6.0"

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP"]

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
```

**Step 2: 建立 app/__init__.py**

```python
"""好日子 App 後端服務"""

__version__ = "0.1.0"
```

**Step 3: 建立基本 main.py**

```python
"""FastAPI 應用程式入口"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(
    title="好日子 API",
    description="歷史氣象統計與節氣分析 API",
    version="0.1.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/health")
async def health_check():
    """健康檢查端點"""
    return {"status": "ok", "version": "0.1.0"}
```

**Step 4: 安裝依賴並驗證**

```bash
cd backend
poetry install
poetry run uvicorn app.main:app --reload --port 8000 &
sleep 3
curl http://localhost:8000/health
# Expected: {"status":"ok","version":"0.1.0"}
pkill -f uvicorn
```

**Step 5: Commit**

```bash
git add -A
git commit -m "feat(backend): initialize FastAPI project with Poetry"
```

---

### Task 0.3: 設定前端環境

**Files:**
- Create: `frontend/package.json`
- Create: `frontend/next.config.js`
- Create: `frontend/tsconfig.json`
- Create: `frontend/tailwind.config.ts`
- Create: `frontend/src/app/layout.tsx`
- Create: `frontend/src/app/page.tsx`

**Step 1: 初始化 Next.js 專案**

```bash
cd frontend
pnpm create next-app@latest . --typescript --tailwind --eslint --app --src-dir --import-alias "@/*" --no-git
```

**Step 2: 安裝額外依賴**

```bash
pnpm add zustand recharts date-fns lucide-react
pnpm add -D @types/node
```

**Step 3: 更新 src/app/page.tsx 為基本首頁**

```tsx
export default function Home() {
  return (
    <main className="flex min-h-screen flex-col items-center justify-center p-24">
      <h1 className="text-4xl font-bold mb-4">好日子</h1>
      <p className="text-xl text-gray-600">
        歷史氣象大數據 × 傳統曆法智慧
      </p>
    </main>
  );
}
```

**Step 4: 驗證前端可運行**

```bash
pnpm dev &
sleep 5
curl -s http://localhost:3000 | grep -o "好日子"
# Expected: 好日子
pkill -f "next dev"
```

**Step 5: Commit**

```bash
cd ..
git add -A
git commit -m "feat(frontend): initialize Next.js 14 with Tailwind"
```

---

### Task 0.4: 設定 Docker Compose 開發環境

**Files:**
- Create: `docker-compose.yml`
- Create: `backend/Dockerfile`

**Step 1: 建立 backend/Dockerfile**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN pip install poetry

COPY pyproject.toml poetry.lock* ./
RUN poetry config virtualenvs.create false \
    && poetry install --no-interaction --no-ansi --no-root

COPY . .

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Step 2: 建立 docker-compose.yml**

```yaml
version: "3.8"

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./data:/data
    environment:
      - DATABASE_URL=sqlite:///data/auspicious.db
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    depends_on:
      - backend
```

**Step 3: 建立 frontend/Dockerfile.dev**

```dockerfile
FROM node:20-alpine

WORKDIR /app

RUN corepack enable && corepack prepare pnpm@latest --activate

COPY package.json pnpm-lock.yaml* ./
RUN pnpm install

COPY . .

CMD ["pnpm", "dev"]
```

**Step 4: Commit**

```bash
git add -A
git commit -m "chore: add Docker Compose development setup"
```

---

## Sprint 1: 數據收集與清洗

### Task 1.1: 建立數據下載腳本

**Files:**
- Create: `data-pipeline/fetch_github.py`
- Test: `data-pipeline/tests/test_fetch.py`

**Step 1: 建立測試檔案**

```python
# data-pipeline/tests/test_fetch.py
"""數據下載功能測試"""

import pytest
from pathlib import Path


def test_build_csv_url():
    """測試 CSV URL 建構"""
    from fetch_github import build_csv_url

    url = build_csv_url("466920", 2023)
    expected = "https://raw.githubusercontent.com/Raingel/historical_weather/master/data/466920/466920-2023.csv"
    assert url == expected


def test_build_csv_url_with_different_station():
    """測試不同站號的 URL"""
    from fetch_github import build_csv_url

    url = build_csv_url("467490", 2020)
    assert "467490" in url
    assert "2020" in url
```

**Step 2: 執行測試確認失敗**

```bash
cd data-pipeline
python -m pytest tests/test_fetch.py -v
# Expected: FAILED - No module named 'fetch_github'
```

**Step 3: 實作 fetch_github.py**

```python
# data-pipeline/fetch_github.py
"""從 GitHub 下載歷史氣象數據"""

import httpx
import pandas as pd
from pathlib import Path
from datetime import datetime
import time


GITHUB_BASE_URL = "https://raw.githubusercontent.com/Raingel/historical_weather/master/data"


def build_csv_url(station_id: str, year: int) -> str:
    """
    建構 CSV 檔案的 GitHub raw URL

    Args:
        station_id: 觀測站代碼，如 '466920'
        year: 年份，如 2023

    Returns:
        完整的 CSV 下載 URL
    """
    return f"{GITHUB_BASE_URL}/{station_id}/{station_id}-{year}.csv"


def download_csv(station_id: str, year: int, output_dir: Path) -> Path | None:
    """
    下載單一年份的 CSV 檔案

    Args:
        station_id: 觀測站代碼
        year: 年份
        output_dir: 輸出目錄

    Returns:
        下載後的檔案路徑，失敗時返回 None
    """
    url = build_csv_url(station_id, year)
    output_path = output_dir / f"{station_id}-{year}.csv"

    try:
        response = httpx.get(url, timeout=30.0)
        response.raise_for_status()

        output_path.write_bytes(response.content)
        print(f"✓ Downloaded: {station_id}-{year}.csv")
        return output_path

    except httpx.HTTPStatusError as e:
        if e.response.status_code == 404:
            print(f"✗ Not found: {station_id}-{year}.csv")
        else:
            print(f"✗ Error downloading {year}: {e}")
        return None


def download_station_data(
    station_id: str,
    start_year: int,
    end_year: int,
    output_dir: Path,
    delay: float = 0.5
) -> list[Path]:
    """
    下載指定站號的多年數據

    Args:
        station_id: 觀測站代碼
        start_year: 起始年份
        end_year: 結束年份（包含）
        output_dir: 輸出目錄
        delay: 每次下載間隔秒數（避免被限流）

    Returns:
        成功下載的檔案路徑列表
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    downloaded = []

    for year in range(start_year, end_year + 1):
        path = download_csv(station_id, year, output_dir)
        if path:
            downloaded.append(path)
        time.sleep(delay)

    print(f"\n總計下載 {len(downloaded)} 個檔案")
    return downloaded


if __name__ == "__main__":
    # 下載台北站 1991-2025 的數據（約 35 年）
    station_id = "466920"
    output_dir = Path("../data/raw")

    download_station_data(
        station_id=station_id,
        start_year=1991,
        end_year=2025,
        output_dir=output_dir
    )
```

**Step 4: 執行測試確認通過**

```bash
python -m pytest tests/test_fetch.py -v
# Expected: 2 passed
```

**Step 5: Commit**

```bash
cd ..
git add -A
git commit -m "feat(data-pipeline): add GitHub data download script"
```

---

### Task 1.2: 下載台北站歷史數據

**Files:**
- Modify: `data-pipeline/fetch_github.py` (執行)
- Create: `data/raw/*.csv` (35+ 個檔案)

**Step 1: 執行下載腳本**

```bash
cd data-pipeline
python fetch_github.py
# Expected: 下載約 35 個 CSV 檔案到 data/raw/
```

**Step 2: 驗證下載結果**

```bash
ls -la ../data/raw/ | head -20
wc -l ../data/raw/*.csv | tail -1
# Expected: 約 12,000+ 行（35年 × 365天）
```

**Step 3: Commit（只記錄腳本，不 commit 大型 CSV）**

```bash
cd ..
git add data-pipeline/
git commit -m "feat(data-pipeline): download Taipei station historical data (1991-2025)"
```

---

### Task 1.3: 建立數據清洗模組

**Files:**
- Create: `data-pipeline/clean.py`
- Test: `data-pipeline/tests/test_clean.py`

**Step 1: 建立測試檔案**

```python
# data-pipeline/tests/test_clean.py
"""數據清洗功能測試"""

import pytest
import pandas as pd
from io import StringIO


def test_clean_temperature_removes_missing_markers():
    """測試清洗溫度欄位的缺失值標記"""
    from clean import clean_temperature_column

    # -9999 是常見的缺失值標記
    df = pd.DataFrame({"temperature_avg": [25.5, -9999, 18.3, -9999.0]})
    result = clean_temperature_column(df, "temperature_avg")

    assert pd.isna(result["temperature_avg"].iloc[1])
    assert pd.isna(result["temperature_avg"].iloc[3])
    assert result["temperature_avg"].iloc[0] == 25.5


def test_clean_temperature_removes_outliers():
    """測試清洗溫度異常值（超過合理範圍）"""
    from clean import clean_temperature_column

    df = pd.DataFrame({"temperature_avg": [25.5, 55.0, -25.0, 18.3]})
    result = clean_temperature_column(df, "temperature_avg")

    # 台灣溫度不可能超過 45°C 或低於 -5°C
    assert pd.isna(result["temperature_avg"].iloc[1])  # 55.0 -> NaN
    assert pd.isna(result["temperature_avg"].iloc[2])  # -25.0 -> NaN


def test_standardize_date_column():
    """測試日期格式標準化"""
    from clean import standardize_date_column

    df = pd.DataFrame({"date": ["2023-02-04", "2023/02/05", "20230206"]})
    result = standardize_date_column(df, "date")

    assert result["date"].dtype == "datetime64[ns]"
    assert len(result) == 3
```

**Step 2: 執行測試確認失敗**

```bash
cd data-pipeline
python -m pytest tests/test_clean.py -v
# Expected: FAILED - No module named 'clean'
```

**Step 3: 實作 clean.py**

```python
# data-pipeline/clean.py
"""數據清洗模組"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional


# 台灣合理的氣象數值範圍
VALID_RANGES = {
    "temperature": (-5, 45),      # 溫度 °C
    "precipitation": (0, 1000),   # 降水量 mm（單日極端值可達 500+）
    "humidity": (0, 100),         # 相對溼度 %
    "wind_speed": (0, 100),       # 風速 m/s
    "sunshine": (0, 14),          # 日照時數（夏至最長約 13.5 小時）
    "pressure": (900, 1100),      # 氣壓 hPa
}

# 常見的缺失值標記
MISSING_MARKERS = [-9999, -9999.0, -99, -99.0, 9999, 9999.0, "", "NA", "N/A", "null"]


def clean_temperature_column(df: pd.DataFrame, column: str) -> pd.DataFrame:
    """
    清洗溫度欄位：移除缺失值標記和異常值

    Args:
        df: 原始 DataFrame
        column: 欄位名稱

    Returns:
        清洗後的 DataFrame（原始 DataFrame 的副本）
    """
    result = df.copy()
    min_val, max_val = VALID_RANGES["temperature"]

    # 轉換為數值型態
    result[column] = pd.to_numeric(result[column], errors="coerce")

    # 替換缺失值標記
    for marker in MISSING_MARKERS:
        if isinstance(marker, (int, float)):
            result.loc[result[column] == marker, column] = np.nan

    # 移除超出範圍的異常值
    result.loc[(result[column] < min_val) | (result[column] > max_val), column] = np.nan

    return result


def standardize_date_column(df: pd.DataFrame, column: str) -> pd.DataFrame:
    """
    標準化日期欄位格式

    Args:
        df: 原始 DataFrame
        column: 日期欄位名稱

    Returns:
        日期欄位已轉換為 datetime64 的 DataFrame
    """
    result = df.copy()
    result[column] = pd.to_datetime(result[column], format="mixed", errors="coerce")
    return result


def clean_precipitation_column(df: pd.DataFrame, column: str) -> pd.DataFrame:
    """清洗降水量欄位"""
    result = df.copy()
    min_val, max_val = VALID_RANGES["precipitation"]

    result[column] = pd.to_numeric(result[column], errors="coerce")

    for marker in MISSING_MARKERS:
        if isinstance(marker, (int, float)):
            result.loc[result[column] == marker, column] = np.nan

    result.loc[(result[column] < min_val) | (result[column] > max_val), column] = np.nan

    # 降水量的缺失通常表示 0（未記錄降水）
    # 但我們保持 NaN 以區分「未記錄」和「確定無雨」

    return result


def clean_csv_file(filepath: Path) -> pd.DataFrame:
    """
    清洗單一 CSV 檔案

    Args:
        filepath: CSV 檔案路徑

    Returns:
        清洗後的 DataFrame
    """
    # 讀取 CSV（GitHub 資料通常是 UTF-8 編碼）
    df = pd.read_csv(filepath, encoding="utf-8")

    # 標準化欄位名稱（根據 Raingel 資料格式）
    column_mapping = {
        "ObsTime": "observed_date",
        "StnPres": "air_pressure",
        "Temperature": "temperature_avg",
        "T Max": "temperature_max",
        "T Min": "temperature_min",
        "RH": "humidity_avg",
        "Precp": "precipitation",
        "PrecpHour": "precipitation_hours",
        "SunShine": "sunshine_hours",
        "WS": "wind_speed_avg",
        "WD": "wind_direction",
        "WSGust": "wind_gust_max",
        "WDGust": "wind_gust_direction",
    }

    # 只保留存在的欄位
    existing_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
    df = df.rename(columns=existing_mapping)

    # 日期標準化
    if "observed_date" in df.columns:
        df = standardize_date_column(df, "observed_date")

    # 清洗各欄位
    temp_columns = ["temperature_avg", "temperature_max", "temperature_min"]
    for col in temp_columns:
        if col in df.columns:
            df = clean_temperature_column(df, col)

    if "precipitation" in df.columns:
        df = clean_precipitation_column(df, "precipitation")

    return df


def merge_and_clean_all(
    input_dir: Path,
    station_id: str,
    output_path: Optional[Path] = None
) -> pd.DataFrame:
    """
    合併並清洗指定站號的所有 CSV 檔案

    Args:
        input_dir: 原始 CSV 目錄
        station_id: 站號
        output_path: 輸出路徑（可選）

    Returns:
        合併清洗後的 DataFrame
    """
    csv_files = sorted(input_dir.glob(f"{station_id}-*.csv"))

    if not csv_files:
        raise FileNotFoundError(f"No CSV files found for station {station_id}")

    all_dfs = []
    for filepath in csv_files:
        print(f"Processing: {filepath.name}")
        df = clean_csv_file(filepath)
        all_dfs.append(df)

    merged = pd.concat(all_dfs, ignore_index=True)

    # 按日期排序並去重
    if "observed_date" in merged.columns:
        merged = merged.sort_values("observed_date")
        merged = merged.drop_duplicates(subset=["observed_date"], keep="last")

    print(f"\n總計 {len(merged)} 筆記錄")
    print(f"日期範圍: {merged['observed_date'].min()} ~ {merged['observed_date'].max()}")

    if output_path:
        merged.to_csv(output_path, index=False)
        print(f"已儲存至: {output_path}")

    return merged


if __name__ == "__main__":
    input_dir = Path("../data/raw")
    output_path = Path("../data/processed/466920_cleaned.csv")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    merge_and_clean_all(input_dir, "466920", output_path)
```

**Step 4: 執行測試確認通過**

```bash
python -m pytest tests/test_clean.py -v
# Expected: 3 passed
```

**Step 5: Commit**

```bash
cd ..
git add -A
git commit -m "feat(data-pipeline): add data cleaning module"
```

---

### Task 1.4: 執行數據清洗並驗證

**Step 1: 執行清洗腳本**

```bash
cd data-pipeline
python clean.py
# Expected: 處理約 35 個檔案，輸出約 12,000+ 筆記錄
```

**Step 2: 驗證清洗結果**

```bash
python -c "
import pandas as pd
df = pd.read_csv('../data/processed/466920_cleaned.csv')
print('資料筆數:', len(df))
print('欄位:', df.columns.tolist())
print('缺失值比例:')
print(df.isnull().mean().round(3))
print('溫度統計:')
print(df['temperature_avg'].describe())
"
```

**Step 3: Commit**

```bash
cd ..
git add data-pipeline/
git commit -m "feat(data-pipeline): clean and merge 35 years of Taipei weather data"
```

---

### Task 1.5: 建立 SQLite 資料庫並載入數據

**Files:**
- Create: `data-pipeline/load.py`
- Create: `backend/app/models/observation.py`
- Create: `backend/app/config.py`

**Step 1: 建立 backend/app/config.py**

```python
# backend/app/config.py
"""應用程式設定"""

from pydantic_settings import BaseSettings
from pathlib import Path


class Settings(BaseSettings):
    """環境設定"""

    app_name: str = "好日子 API"
    debug: bool = True

    # 資料庫設定
    database_url: str = "sqlite:///./data/auspicious.db"

    # 資料路徑
    data_dir: Path = Path("./data")

    class Config:
        env_file = ".env"


settings = Settings()
```

**Step 2: 建立 backend/app/models/observation.py**

```python
# backend/app/models/observation.py
"""觀測數據資料模型"""

from sqlalchemy import Column, Integer, String, Float, Date, DateTime, UniqueConstraint
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func

Base = declarative_base()


class RawObservation(Base):
    """原始觀測數據表"""

    __tablename__ = "raw_observations"

    id = Column(Integer, primary_key=True, autoincrement=True)
    station_id = Column(String(10), nullable=False, index=True)
    observed_date = Column(Date, nullable=False, index=True)

    # 溫度
    temperature_avg = Column(Float, nullable=True)
    temperature_max = Column(Float, nullable=True)
    temperature_min = Column(Float, nullable=True)

    # 降水
    precipitation = Column(Float, nullable=True)

    # 其他氣象要素
    humidity_avg = Column(Float, nullable=True)
    wind_speed_avg = Column(Float, nullable=True)
    wind_gust_max = Column(Float, nullable=True)
    sunshine_hours = Column(Float, nullable=True)
    air_pressure = Column(Float, nullable=True)

    # 元數據
    data_source = Column(String(20), default="github")
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())

    __table_args__ = (
        UniqueConstraint("station_id", "observed_date", name="uq_station_date"),
    )

    def __repr__(self):
        return f"<RawObservation {self.station_id} {self.observed_date}>"
```

**Step 3: 建立 data-pipeline/load.py**

```python
# data-pipeline/load.py
"""載入清洗後數據至 SQLite"""

import pandas as pd
from pathlib import Path
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import sys

# 將 backend 加入 path 以使用 models
sys.path.insert(0, str(Path(__file__).parent.parent / "backend"))

from app.models.observation import Base, RawObservation


def load_csv_to_sqlite(
    csv_path: Path,
    db_path: Path,
    station_id: str
) -> int:
    """
    將清洗後的 CSV 載入 SQLite 資料庫

    Args:
        csv_path: CSV 檔案路徑
        db_path: SQLite 資料庫路徑
        station_id: 觀測站代碼

    Returns:
        載入的記錄數
    """
    # 建立資料庫連線
    engine = create_engine(f"sqlite:///{db_path}")
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()

    # 讀取 CSV
    df = pd.read_csv(csv_path, parse_dates=["observed_date"])

    # 轉換為 ORM 物件並插入
    count = 0
    for _, row in df.iterrows():
        obs = RawObservation(
            station_id=station_id,
            observed_date=row["observed_date"].date(),
            temperature_avg=row.get("temperature_avg") if pd.notna(row.get("temperature_avg")) else None,
            temperature_max=row.get("temperature_max") if pd.notna(row.get("temperature_max")) else None,
            temperature_min=row.get("temperature_min") if pd.notna(row.get("temperature_min")) else None,
            precipitation=row.get("precipitation") if pd.notna(row.get("precipitation")) else None,
            humidity_avg=row.get("humidity_avg") if pd.notna(row.get("humidity_avg")) else None,
            wind_speed_avg=row.get("wind_speed_avg") if pd.notna(row.get("wind_speed_avg")) else None,
            sunshine_hours=row.get("sunshine_hours") if pd.notna(row.get("sunshine_hours")) else None,
            air_pressure=row.get("air_pressure") if pd.notna(row.get("air_pressure")) else None,
            data_source="github",
        )
        session.merge(obs)  # merge 支援 upsert
        count += 1

        if count % 1000 == 0:
            session.commit()
            print(f"已載入 {count} 筆...")

    session.commit()
    session.close()

    print(f"\n總計載入 {count} 筆記錄至 {db_path}")
    return count


if __name__ == "__main__":
    csv_path = Path("../data/processed/466920_cleaned.csv")
    db_path = Path("../data/auspicious.db")

    load_csv_to_sqlite(csv_path, db_path, "466920")
```

**Step 4: 執行載入腳本**

```bash
cd data-pipeline
python load.py
# Expected: 載入約 12,000+ 筆記錄
```

**Step 5: 驗證資料庫**

```bash
sqlite3 ../data/auspicious.db "SELECT COUNT(*) FROM raw_observations;"
sqlite3 ../data/auspicious.db "SELECT MIN(observed_date), MAX(observed_date) FROM raw_observations;"
# Expected: 約 12000+ 筆，日期範圍 1991~2025
```

**Step 6: Commit**

```bash
cd ..
git add backend/app/config.py backend/app/models/
git add data-pipeline/load.py
git commit -m "feat: add SQLite database schema and data loading"
```

---

## Sprint 2: 數據分析引擎

### Task 2.1: 建立統計計算引擎

**Files:**
- Create: `backend/app/analytics/engine.py`
- Test: `backend/tests/test_analytics.py`

**Step 1: 建立測試檔案**

```python
# backend/tests/test_analytics.py
"""統計分析引擎測試"""

import pytest
import pandas as pd
import numpy as np
from datetime import date


def test_compute_basic_stats():
    """測試基本統計計算"""
    from app.analytics.engine import compute_basic_stats

    data = pd.Series([10.0, 15.0, 20.0, 25.0, 30.0])
    stats = compute_basic_stats(data)

    assert stats["mean"] == 20.0
    assert stats["median"] == 20.0
    assert "std_dev" in stats
    assert "percentile_25" in stats
    assert "percentile_75" in stats


def test_compute_precipitation_stats():
    """測試降水統計計算"""
    from app.analytics.engine import compute_precipitation_stats

    # 10 天中有 3 天下雨
    precip = pd.Series([0, 0, 5.0, 0, 0, 10.0, 0, 0, 0, 60.0])
    stats = compute_precipitation_stats(precip)

    assert stats["probability"] == 0.3  # 3/10
    assert stats["heavy_rain_probability"] == 0.1  # 1/10 (>50mm)
    assert stats["max_recorded_mm"] == 60.0


def test_compute_weather_tendency():
    """測試天氣傾向計算"""
    from app.analytics.engine import compute_weather_tendency

    # 模擬數據：5 天晴、3 天陰、2 天雨
    precip = pd.Series([0, 0, 0, 0, 0, 0.5, 0.5, 0.5, 5.0, 10.0])
    sunshine = pd.Series([8, 7, 9, 6, 8, 1, 2, 1, 0, 0])

    tendency = compute_weather_tendency(precip, sunshine)

    assert "sunny" in tendency
    assert "cloudy" in tendency
    assert "rainy" in tendency
    assert tendency["dominant"] in ["sunny", "cloudy", "rainy"]
```

**Step 2: 執行測試確認失敗**

```bash
cd backend
poetry run pytest tests/test_analytics.py -v
# Expected: FAILED - No module named 'app.analytics.engine'
```

**Step 3: 實作 engine.py**

```python
# backend/app/analytics/engine.py
"""歷史天氣統計分析引擎"""

import pandas as pd
import numpy as np
from datetime import date
from typing import Optional
from sqlalchemy.orm import Session

from app.models.observation import RawObservation


def compute_basic_stats(data: pd.Series) -> dict:
    """
    計算基本統計量

    Args:
        data: 數值型 Series

    Returns:
        包含 mean, median, std_dev, percentiles 的字典
    """
    clean_data = data.dropna()

    if len(clean_data) == 0:
        return {
            "mean": None,
            "median": None,
            "std_dev": None,
            "percentile_25": None,
            "percentile_75": None,
            "count": 0,
        }

    return {
        "mean": round(float(clean_data.mean()), 2),
        "median": round(float(clean_data.median()), 2),
        "std_dev": round(float(clean_data.std()), 2),
        "percentile_25": round(float(clean_data.quantile(0.25)), 2),
        "percentile_75": round(float(clean_data.quantile(0.75)), 2),
        "count": len(clean_data),
    }


def compute_precipitation_stats(precip: pd.Series) -> dict:
    """
    計算降水統計

    Args:
        precip: 降水量 Series (mm)

    Returns:
        降水統計字典
    """
    clean_data = precip.dropna()

    if len(clean_data) == 0:
        return {
            "probability": None,
            "avg_amount_when_rain_mm": None,
            "heavy_rain_probability": None,
            "max_recorded_mm": None,
        }

    has_rain = clean_data > 0.1  # >0.1mm 視為有雨
    heavy_rain = clean_data > 50  # >50mm 視為大雨

    rainy_days = clean_data[has_rain]

    return {
        "probability": round(float(has_rain.mean()), 4),
        "avg_amount_when_rain_mm": round(float(rainy_days.mean()), 2) if len(rainy_days) > 0 else 0,
        "heavy_rain_probability": round(float(heavy_rain.mean()), 4),
        "max_recorded_mm": round(float(clean_data.max()), 2),
    }


def compute_weather_tendency(precip: pd.Series, sunshine: pd.Series) -> dict:
    """
    計算天氣傾向（晴/陰/雨比例）

    Args:
        precip: 降水量 Series
        sunshine: 日照時數 Series

    Returns:
        天氣傾向字典
    """
    # 對齊數據
    df = pd.DataFrame({"precip": precip, "sunshine": sunshine}).dropna()

    if len(df) == 0:
        return {
            "sunny": None,
            "cloudy": None,
            "rainy": None,
            "dominant": None,
        }

    total = len(df)

    # 分類邏輯：
    # 晴：降水 < 0.1mm 且 日照 > 3 小時
    # 雨：降水 >= 1mm
    # 陰：其他
    sunny_mask = (df["precip"] < 0.1) & (df["sunshine"] > 3)
    rainy_mask = df["precip"] >= 1.0

    sunny = float(sunny_mask.sum()) / total
    rainy = float(rainy_mask.sum()) / total
    cloudy = 1.0 - sunny - rainy
    cloudy = max(cloudy, 0)  # 確保不為負

    tendencies = {
        "sunny": round(sunny, 4),
        "cloudy": round(cloudy, 4),
        "rainy": round(rainy, 4),
    }
    tendencies["dominant"] = max(tendencies, key=tendencies.get)

    return tendencies


class HistoricalWeatherAnalyzer:
    """歷史天氣統計分析器"""

    def __init__(self, session: Session, station_id: str):
        self.session = session
        self.station_id = station_id

    def get_data_for_date(
        self,
        month: int,
        day: int,
        window: int = 3
    ) -> pd.DataFrame:
        """
        取得指定月日的歷史數據（含滑動視窗）

        Args:
            month: 月份 (1-12)
            day: 日 (1-31)
            window: 滑動視窗半徑

        Returns:
            歷史觀測數據 DataFrame
        """
        from sqlalchemy import extract, and_

        # 計算日期範圍
        target_doy = date(2000, month, day).timetuple().tm_yday

        # 查詢符合條件的所有歷史數據
        query = self.session.query(RawObservation).filter(
            RawObservation.station_id == self.station_id
        ).all()

        # 轉換為 DataFrame
        records = []
        for obs in query:
            obs_doy = obs.observed_date.timetuple().tm_yday
            # 檢查是否在滑動視窗內
            diff = abs(obs_doy - target_doy)
            # 處理跨年情況
            diff = min(diff, 365 - diff)

            if diff <= window:
                records.append({
                    "observed_date": obs.observed_date,
                    "year": obs.observed_date.year,
                    "temperature_avg": obs.temperature_avg,
                    "temperature_max": obs.temperature_max,
                    "temperature_min": obs.temperature_min,
                    "precipitation": obs.precipitation,
                    "humidity_avg": obs.humidity_avg,
                    "sunshine_hours": obs.sunshine_hours,
                    "distance": diff,  # 與目標日期的距離
                })

        return pd.DataFrame(records)

    def compute_daily_stats(
        self,
        month: int,
        day: int,
        window: int = 3
    ) -> dict:
        """
        計算指定日期的完整統計

        Args:
            month: 月份
            day: 日
            window: 滑動視窗半徑

        Returns:
            完整統計字典
        """
        df = self.get_data_for_date(month, day, window)

        if len(df) == 0:
            return {"error": "No data available"}

        # 溫度統計
        temp_stats = {
            "avg": compute_basic_stats(df["temperature_avg"]),
            "daily_max": {
                **compute_basic_stats(df["temperature_max"]),
                "historical_record": df["temperature_max"].max(),
                "record_year": int(df.loc[df["temperature_max"].idxmax(), "year"]) if df["temperature_max"].notna().any() else None,
            },
            "daily_min": {
                **compute_basic_stats(df["temperature_min"]),
                "historical_record": df["temperature_min"].min(),
                "record_year": int(df.loc[df["temperature_min"].idxmin(), "year"]) if df["temperature_min"].notna().any() else None,
            },
        }

        # 降水統計
        precip_stats = compute_precipitation_stats(df["precipitation"])

        # 天氣傾向
        tendency = compute_weather_tendency(
            df["precipitation"],
            df["sunshine_hours"]
        )

        return {
            "station_id": self.station_id,
            "month_day": f"{month:02d}-{day:02d}",
            "years_analyzed": df["year"].nunique(),
            "start_year": int(df["year"].min()),
            "end_year": int(df["year"].max()),
            "temperature": temp_stats,
            "precipitation": precip_stats,
            "weather_tendency": tendency,
        }
```

**Step 4: 執行測試確認通過**

```bash
poetry run pytest tests/test_analytics.py -v
# Expected: 3 passed
```

**Step 5: Commit**

```bash
cd ..
git add -A
git commit -m "feat(backend): add historical weather analytics engine"
```

---

### Task 2.2: 建立統計快照計算腳本

**Files:**
- Create: `data-pipeline/compute_snapshots.py`
- Create: `backend/app/models/statistics.py`

**Step 1: 建立 statistics 模型**

```python
# backend/app/models/statistics.py
"""統計快照資料模型"""

from sqlalchemy import Column, Integer, String, Float, DateTime, UniqueConstraint
from sqlalchemy.sql import func

from app.models.observation import Base


class DailyStatistics(Base):
    """每日統計快照表"""

    __tablename__ = "daily_statistics"

    id = Column(Integer, primary_key=True, autoincrement=True)
    station_id = Column(String(10), nullable=False, index=True)
    month_day = Column(String(5), nullable=False)  # 'MM-DD' 格式

    # 分析期間
    years_analyzed = Column(Integer)
    start_year = Column(Integer)
    end_year = Column(Integer)

    # 溫度統計
    temp_avg_mean = Column(Float)
    temp_avg_median = Column(Float)
    temp_avg_stddev = Column(Float)
    temp_max_mean = Column(Float)
    temp_max_record = Column(Float)
    temp_min_mean = Column(Float)
    temp_min_record = Column(Float)

    # 降水統計
    precip_probability = Column(Float)
    precip_avg_when_rain = Column(Float)
    precip_heavy_prob = Column(Float)
    precip_max_record = Column(Float)

    # 天氣傾向
    tendency_sunny = Column(Float)
    tendency_cloudy = Column(Float)
    tendency_rainy = Column(Float)

    # 元數據
    computed_at = Column(DateTime, server_default=func.now())

    __table_args__ = (
        UniqueConstraint("station_id", "month_day", name="uq_station_monthday"),
    )
```

**Step 2: 建立 compute_snapshots.py**

```python
# data-pipeline/compute_snapshots.py
"""計算並儲存 366 天的統計快照"""

import sys
from pathlib import Path
from datetime import date
from calendar import monthrange

sys.path.insert(0, str(Path(__file__).parent.parent / "backend"))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from app.models.observation import Base, RawObservation
from app.models.statistics import DailyStatistics
from app.analytics.engine import HistoricalWeatherAnalyzer


def compute_all_daily_snapshots(
    db_path: Path,
    station_id: str,
    window: int = 3
) -> int:
    """
    計算全年 366 天的統計快照

    Args:
        db_path: 資料庫路徑
        station_id: 觀測站代碼
        window: 滑動視窗半徑

    Returns:
        計算的快照數量
    """
    engine = create_engine(f"sqlite:///{db_path}")
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()

    analyzer = HistoricalWeatherAnalyzer(session, station_id)
    count = 0

    # 遍歷所有月日組合（含 2/29）
    for month in range(1, 13):
        days_in_month = 29 if month == 2 else monthrange(2000, month)[1]

        for day in range(1, days_in_month + 1):
            print(f"Computing {month:02d}-{day:02d}...", end=" ")

            stats = analyzer.compute_daily_stats(month, day, window)

            if "error" in stats:
                print("SKIP (no data)")
                continue

            # 建立或更新快照
            snapshot = DailyStatistics(
                station_id=station_id,
                month_day=f"{month:02d}-{day:02d}",
                years_analyzed=stats["years_analyzed"],
                start_year=stats["start_year"],
                end_year=stats["end_year"],
                temp_avg_mean=stats["temperature"]["avg"]["mean"],
                temp_avg_median=stats["temperature"]["avg"]["median"],
                temp_avg_stddev=stats["temperature"]["avg"]["std_dev"],
                temp_max_mean=stats["temperature"]["daily_max"]["mean"],
                temp_max_record=stats["temperature"]["daily_max"]["historical_record"],
                temp_min_mean=stats["temperature"]["daily_min"]["mean"],
                temp_min_record=stats["temperature"]["daily_min"]["historical_record"],
                precip_probability=stats["precipitation"]["probability"],
                precip_avg_when_rain=stats["precipitation"]["avg_amount_when_rain_mm"],
                precip_heavy_prob=stats["precipitation"]["heavy_rain_probability"],
                precip_max_record=stats["precipitation"]["max_recorded_mm"],
                tendency_sunny=stats["weather_tendency"]["sunny"],
                tendency_cloudy=stats["weather_tendency"]["cloudy"],
                tendency_rainy=stats["weather_tendency"]["rainy"],
            )

            session.merge(snapshot)
            count += 1
            print("OK")

        session.commit()
        print(f"Month {month} completed.")

    session.close()
    print(f"\n總計計算 {count} 個統計快照")
    return count


if __name__ == "__main__":
    db_path = Path("../data/auspicious.db")
    compute_all_daily_snapshots(db_path, "466920")
```

**Step 3: 執行計算（這會花幾分鐘）**

```bash
cd data-pipeline
python compute_snapshots.py
# Expected: 計算 366 個快照
```

**Step 4: 驗證快照**

```bash
sqlite3 ../data/auspicious.db "SELECT COUNT(*) FROM daily_statistics;"
sqlite3 ../data/auspicious.db "SELECT * FROM daily_statistics WHERE month_day = '02-04';"
# Expected: 366 筆，且 02-04 有完整統計
```

**Step 5: Commit**

```bash
cd ..
git add -A
git commit -m "feat: add daily statistics snapshot computation"
```

---

## Sprint 3: 後端 API

### Task 3.1: 建立資料庫連線管理

**Files:**
- Create: `backend/app/database.py`
- Modify: `backend/app/main.py`

**Step 1: 建立 database.py**

```python
# backend/app/database.py
"""資料庫連線管理"""

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from typing import Generator

from app.config import settings
from app.models.observation import Base


engine = create_engine(
    settings.database_url,
    connect_args={"check_same_thread": False}  # SQLite 專用
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


def init_db():
    """初始化資料庫表"""
    Base.metadata.create_all(bind=engine)


def get_db() -> Generator[Session, None, None]:
    """取得資料庫 session（FastAPI 依賴注入用）"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

**Step 2: 更新 main.py**

```python
# backend/app/main.py
"""FastAPI 應用程式入口"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.database import init_db
from app.api.v1 import weather, stations

app = FastAPI(
    title="好日子 API",
    description="歷史氣象統計與節氣分析 API",
    version="0.1.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup():
    init_db()


@app.get("/health")
async def health_check():
    """健康檢查端點"""
    return {"status": "ok", "version": "0.1.0"}


# 註冊路由
app.include_router(weather.router, prefix="/api/v1/weather", tags=["weather"])
app.include_router(stations.router, prefix="/api/v1/stations", tags=["stations"])
```

**Step 3: Commit**

```bash
git add -A
git commit -m "feat(backend): add database connection management"
```

---

### Task 3.2: 建立天氣查詢 API

**Files:**
- Create: `backend/app/api/v1/weather.py`
- Create: `backend/app/schemas/weather.py`
- Test: `backend/tests/test_api_weather.py`

**Step 1: 建立 schemas**

```python
# backend/app/schemas/weather.py
"""天氣 API 回應 Schema"""

from pydantic import BaseModel
from typing import Optional
from datetime import datetime


class StationInfo(BaseModel):
    id: str
    name: str
    city: Optional[str] = None


class TemperatureStats(BaseModel):
    mean: Optional[float]
    median: Optional[float]
    std_dev: Optional[float]


class TemperatureRecord(BaseModel):
    mean: Optional[float]
    historical_record: Optional[float]
    record_year: Optional[int] = None


class TemperatureResponse(BaseModel):
    avg: TemperatureStats
    daily_max: TemperatureRecord
    daily_min: TemperatureRecord


class PrecipitationResponse(BaseModel):
    probability: Optional[float]
    avg_amount_when_rain_mm: Optional[float]
    heavy_rain_probability: Optional[float]
    max_recorded_mm: Optional[float]


class WeatherTendencyResponse(BaseModel):
    sunny: Optional[float]
    cloudy: Optional[float]
    rainy: Optional[float]
    dominant: Optional[str]


class AnalysisPeriod(BaseModel):
    years_analyzed: int
    start_year: int
    end_year: int


class DailyWeatherResponse(BaseModel):
    station: StationInfo
    date: str
    analysis_period: AnalysisPeriod
    temperature: TemperatureResponse
    precipitation: PrecipitationResponse
    weather_tendency: WeatherTendencyResponse


class ApiResponse(BaseModel):
    status: str = "ok"
    data: DailyWeatherResponse


class ErrorResponse(BaseModel):
    status: str = "error"
    message: str
```

**Step 2: 建立 weather router**

```python
# backend/app/api/v1/weather.py
"""天氣查詢 API"""

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
import re

from app.database import get_db
from app.models.statistics import DailyStatistics
from app.schemas.weather import (
    ApiResponse,
    DailyWeatherResponse,
    StationInfo,
    AnalysisPeriod,
    TemperatureResponse,
    TemperatureStats,
    TemperatureRecord,
    PrecipitationResponse,
    WeatherTendencyResponse,
)

router = APIRouter()

# 觀測站資訊對照表
STATION_INFO = {
    "466920": {"name": "臺北", "city": "臺北市"},
    "467490": {"name": "臺中", "city": "臺中市"},
    "467410": {"name": "臺南", "city": "臺南市"},
    "467440": {"name": "高雄", "city": "高雄市"},
    "466990": {"name": "花蓮", "city": "花蓮縣"},
    "467660": {"name": "臺東", "city": "臺東縣"},
}


def validate_month_day(month_day: str) -> tuple[int, int]:
    """驗證並解析 MM-DD 格式"""
    pattern = r"^(0[1-9]|1[0-2])-(0[1-9]|[12]\d|3[01])$"
    if not re.match(pattern, month_day):
        raise HTTPException(status_code=400, detail="Invalid date format. Use MM-DD.")

    month, day = map(int, month_day.split("-"))

    # 基本日期驗證
    if month == 2 and day > 29:
        raise HTTPException(status_code=400, detail="Invalid date: February has at most 29 days.")
    if month in [4, 6, 9, 11] and day > 30:
        raise HTTPException(status_code=400, detail=f"Invalid date: Month {month} has at most 30 days.")

    return month, day


@router.get("/daily/{station_id}/{month_day}", response_model=ApiResponse)
async def get_daily_statistics(
    station_id: str,
    month_day: str,
    db: Session = Depends(get_db)
):
    """
    查詢指定站的指定日期歷史統計

    - **station_id**: 觀測站代碼 (如 466920)
    - **month_day**: 日期，格式 MM-DD (如 02-04)
    """
    # 驗證參數
    validate_month_day(month_day)

    if station_id not in STATION_INFO:
        raise HTTPException(status_code=404, detail=f"Station {station_id} not found")

    # 查詢統計快照
    stats = db.query(DailyStatistics).filter(
        DailyStatistics.station_id == station_id,
        DailyStatistics.month_day == month_day
    ).first()

    if not stats:
        raise HTTPException(
            status_code=404,
            detail=f"No statistics available for {station_id} on {month_day}"
        )

    # 組裝回應
    station_info = STATION_INFO[station_id]

    response_data = DailyWeatherResponse(
        station=StationInfo(
            id=station_id,
            name=station_info["name"],
            city=station_info["city"]
        ),
        date=month_day,
        analysis_period=AnalysisPeriod(
            years_analyzed=stats.years_analyzed,
            start_year=stats.start_year,
            end_year=stats.end_year
        ),
        temperature=TemperatureResponse(
            avg=TemperatureStats(
                mean=stats.temp_avg_mean,
                median=stats.temp_avg_median,
                std_dev=stats.temp_avg_stddev
            ),
            daily_max=TemperatureRecord(
                mean=stats.temp_max_mean,
                historical_record=stats.temp_max_record
            ),
            daily_min=TemperatureRecord(
                mean=stats.temp_min_mean,
                historical_record=stats.temp_min_record
            )
        ),
        precipitation=PrecipitationResponse(
            probability=stats.precip_probability,
            avg_amount_when_rain_mm=stats.precip_avg_when_rain,
            heavy_rain_probability=stats.precip_heavy_prob,
            max_recorded_mm=stats.precip_max_record
        ),
        weather_tendency=WeatherTendencyResponse(
            sunny=stats.tendency_sunny,
            cloudy=stats.tendency_cloudy,
            rainy=stats.tendency_rainy,
            dominant="sunny" if (stats.tendency_sunny or 0) >= max(stats.tendency_cloudy or 0, stats.tendency_rainy or 0) else ("cloudy" if (stats.tendency_cloudy or 0) >= (stats.tendency_rainy or 0) else "rainy")
        )
    )

    return ApiResponse(status="ok", data=response_data)


@router.get("/today/{station_id}")
async def get_today_statistics(
    station_id: str,
    db: Session = Depends(get_db)
):
    """查詢今日的歷史統計"""
    from datetime import date
    today = date.today()
    month_day = f"{today.month:02d}-{today.day:02d}"

    return await get_daily_statistics(station_id, month_day, db)
```

**Step 3: 建立 stations router**

```python
# backend/app/api/v1/stations.py
"""觀測站 API"""

from fastapi import APIRouter
from pydantic import BaseModel
from typing import Optional

router = APIRouter()


class Station(BaseModel):
    id: str
    name: str
    name_en: Optional[str] = None
    city: str
    latitude: float
    longitude: float
    data_start_year: int


STATIONS = [
    Station(
        id="466920",
        name="臺北",
        name_en="Taipei",
        city="臺北市",
        latitude=25.0376,
        longitude=121.5148,
        data_start_year=1896
    ),
]


@router.get("")
async def list_stations():
    """取得所有觀測站列表"""
    return {"status": "ok", "data": STATIONS}


@router.get("/{station_id}")
async def get_station(station_id: str):
    """取得指定觀測站資訊"""
    for station in STATIONS:
        if station.id == station_id:
            return {"status": "ok", "data": station}

    return {"status": "error", "message": f"Station {station_id} not found"}
```

**Step 4: 建立 `__init__.py`**

```python
# backend/app/api/__init__.py
"""API 模組"""

# backend/app/api/v1/__init__.py
"""API v1 模組"""
```

**Step 5: 測試 API**

```bash
cd backend
poetry run uvicorn app.main:app --reload --port 8000 &
sleep 3
curl "http://localhost:8000/api/v1/weather/daily/466920/02-04" | python -m json.tool
curl "http://localhost:8000/api/v1/stations" | python -m json.tool
pkill -f uvicorn
```

**Step 6: Commit**

```bash
cd ..
git add -A
git commit -m "feat(backend): add weather and stations API endpoints"
```

---

## Sprint 4: 前端 Web（簡化版）

### Task 4.1: 設定 API 客戶端

**Files:**
- Create: `frontend/src/lib/api.ts`
- Create: `frontend/src/lib/types.ts`

**Step 1: 建立型別定義**

```typescript
// frontend/src/lib/types.ts

export interface StationInfo {
  id: string;
  name: string;
  city?: string;
}

export interface TemperatureStats {
  mean: number | null;
  median: number | null;
  std_dev: number | null;
}

export interface TemperatureRecord {
  mean: number | null;
  historical_record: number | null;
  record_year?: number | null;
}

export interface TemperatureResponse {
  avg: TemperatureStats;
  daily_max: TemperatureRecord;
  daily_min: TemperatureRecord;
}

export interface PrecipitationResponse {
  probability: number | null;
  avg_amount_when_rain_mm: number | null;
  heavy_rain_probability: number | null;
  max_recorded_mm: number | null;
}

export interface WeatherTendencyResponse {
  sunny: number | null;
  cloudy: number | null;
  rainy: number | null;
  dominant: string | null;
}

export interface AnalysisPeriod {
  years_analyzed: number;
  start_year: number;
  end_year: number;
}

export interface DailyWeatherData {
  station: StationInfo;
  date: string;
  analysis_period: AnalysisPeriod;
  temperature: TemperatureResponse;
  precipitation: PrecipitationResponse;
  weather_tendency: WeatherTendencyResponse;
}

export interface ApiResponse<T> {
  status: "ok" | "error";
  data?: T;
  message?: string;
}
```

**Step 2: 建立 API 客戶端**

```typescript
// frontend/src/lib/api.ts

import { ApiResponse, DailyWeatherData, StationInfo } from "./types";

const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8000";

export async function fetchDailyWeather(
  stationId: string,
  monthDay: string
): Promise<DailyWeatherData> {
  const response = await fetch(
    `${API_BASE_URL}/api/v1/weather/daily/${stationId}/${monthDay}`
  );

  if (!response.ok) {
    throw new Error(`API error: ${response.status}`);
  }

  const result: ApiResponse<DailyWeatherData> = await response.json();

  if (result.status !== "ok" || !result.data) {
    throw new Error(result.message || "Unknown error");
  }

  return result.data;
}

export async function fetchTodayWeather(
  stationId: string
): Promise<DailyWeatherData> {
  const response = await fetch(
    `${API_BASE_URL}/api/v1/weather/today/${stationId}`
  );

  if (!response.ok) {
    throw new Error(`API error: ${response.status}`);
  }

  const result: ApiResponse<DailyWeatherData> = await response.json();

  if (result.status !== "ok" || !result.data) {
    throw new Error(result.message || "Unknown error");
  }

  return result.data;
}

export async function fetchStations(): Promise<StationInfo[]> {
  const response = await fetch(`${API_BASE_URL}/api/v1/stations`);

  if (!response.ok) {
    throw new Error(`API error: ${response.status}`);
  }

  const result: ApiResponse<StationInfo[]> = await response.json();

  if (result.status !== "ok" || !result.data) {
    throw new Error(result.message || "Unknown error");
  }

  return result.data;
}
```

**Step 3: Commit**

```bash
git add -A
git commit -m "feat(frontend): add API client and type definitions"
```

---

### Task 4.2: 建立首頁組件

**Files:**
- Modify: `frontend/src/app/page.tsx`
- Create: `frontend/src/components/WeatherCard.tsx`
- Create: `frontend/src/components/TendencyChart.tsx`

**Step 1: 建立 WeatherCard 組件**

```tsx
// frontend/src/components/WeatherCard.tsx
"use client";

import { DailyWeatherData } from "@/lib/types";

interface WeatherCardProps {
  data: DailyWeatherData;
}

export function WeatherCard({ data }: WeatherCardProps) {
  const { station, date, analysis_period, temperature, precipitation, weather_tendency } = data;

  return (
    <div className="bg-white rounded-lg shadow-lg p-6 max-w-2xl mx-auto">
      {/* 標題區 */}
      <div className="text-center mb-6">
        <h2 className="text-2xl font-bold text-gray-800">
          {station.name}觀測站
        </h2>
        <p className="text-gray-500">
          {date} 歷史天氣統計
        </p>
        <p className="text-sm text-gray-400">
          分析期間：{analysis_period.start_year} - {analysis_period.end_year}
          （{analysis_period.years_analyzed} 年）
        </p>
      </div>

      {/* 溫度區 */}
      <div className="grid grid-cols-3 gap-4 mb-6">
        <div className="text-center p-4 bg-blue-50 rounded-lg">
          <p className="text-sm text-gray-500">平均溫度</p>
          <p className="text-3xl font-bold text-blue-600">
            {temperature.avg.mean?.toFixed(1)}°C
          </p>
        </div>
        <div className="text-center p-4 bg-red-50 rounded-lg">
          <p className="text-sm text-gray-500">歷史最高</p>
          <p className="text-3xl font-bold text-red-600">
            {temperature.daily_max.historical_record?.toFixed(1)}°C
          </p>
        </div>
        <div className="text-center p-4 bg-cyan-50 rounded-lg">
          <p className="text-sm text-gray-500">歷史最低</p>
          <p className="text-3xl font-bold text-cyan-600">
            {temperature.daily_min.historical_record?.toFixed(1)}°C
          </p>
        </div>
      </div>

      {/* 降水區 */}
      <div className="mb-6">
        <h3 className="text-lg font-semibold mb-2">降水統計</h3>
        <div className="flex items-center gap-4">
          <div className="flex-1 bg-gray-100 rounded-full h-4">
            <div
              className="bg-blue-500 h-4 rounded-full"
              style={{ width: `${(precipitation.probability || 0) * 100}%` }}
            />
          </div>
          <span className="text-lg font-bold">
            {((precipitation.probability || 0) * 100).toFixed(0)}%
          </span>
        </div>
        <p className="text-sm text-gray-500 mt-1">
          有雨時平均降水量：{precipitation.avg_amount_when_rain_mm?.toFixed(1)} mm
        </p>
      </div>

      {/* 天氣傾向 */}
      <div>
        <h3 className="text-lg font-semibold mb-2">天氣傾向</h3>
        <div className="flex gap-2">
          <div
            className="bg-yellow-400 h-8 rounded"
            style={{ width: `${(weather_tendency.sunny || 0) * 100}%` }}
            title={`晴 ${((weather_tendency.sunny || 0) * 100).toFixed(0)}%`}
          />
          <div
            className="bg-gray-400 h-8 rounded"
            style={{ width: `${(weather_tendency.cloudy || 0) * 100}%` }}
            title={`陰 ${((weather_tendency.cloudy || 0) * 100).toFixed(0)}%`}
          />
          <div
            className="bg-blue-400 h-8 rounded"
            style={{ width: `${(weather_tendency.rainy || 0) * 100}%` }}
            title={`雨 ${((weather_tendency.rainy || 0) * 100).toFixed(0)}%`}
          />
        </div>
        <div className="flex justify-between text-sm text-gray-500 mt-1">
          <span>☀️ {((weather_tendency.sunny || 0) * 100).toFixed(0)}%</span>
          <span>☁️ {((weather_tendency.cloudy || 0) * 100).toFixed(0)}%</span>
          <span>🌧️ {((weather_tendency.rainy || 0) * 100).toFixed(0)}%</span>
        </div>
      </div>
    </div>
  );
}
```

**Step 2: 更新首頁**

```tsx
// frontend/src/app/page.tsx
"use client";

import { useEffect, useState } from "react";
import { fetchTodayWeather } from "@/lib/api";
import { DailyWeatherData } from "@/lib/types";
import { WeatherCard } from "@/components/WeatherCard";

export default function Home() {
  const [data, setData] = useState<DailyWeatherData | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    async function loadData() {
      try {
        const result = await fetchTodayWeather("466920");
        setData(result);
      } catch (err) {
        setError(err instanceof Error ? err.message : "Unknown error");
      } finally {
        setLoading(false);
      }
    }

    loadData();
  }, []);

  return (
    <main className="min-h-screen bg-gradient-to-b from-blue-100 to-white p-8">
      <div className="max-w-4xl mx-auto">
        <header className="text-center mb-8">
          <h1 className="text-4xl font-bold text-gray-800 mb-2">好日子</h1>
          <p className="text-xl text-gray-600">
            歷史氣象大數據 × 傳統曆法智慧
          </p>
        </header>

        {loading && (
          <div className="text-center py-12">
            <p className="text-gray-500">載入中...</p>
          </div>
        )}

        {error && (
          <div className="text-center py-12">
            <p className="text-red-500">錯誤：{error}</p>
            <p className="text-gray-500 mt-2">
              請確認後端 API 已啟動（http://localhost:8000）
            </p>
          </div>
        )}

        {data && <WeatherCard data={data} />}
      </div>
    </main>
  );
}
```

**Step 3: 建立環境變數檔**

```bash
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > frontend/.env.local
```

**Step 4: 測試前後端整合**

```bash
# Terminal 1: 啟動後端
cd backend && poetry run uvicorn app.main:app --reload --port 8000

# Terminal 2: 啟動前端
cd frontend && pnpm dev

# 瀏覽 http://localhost:3000 應該看到今日天氣統計
```

**Step 5: Commit**

```bash
git add -A
git commit -m "feat(frontend): add WeatherCard component and homepage"
```

---

## Sprint 5-6: 整合與部署（簡化版）

### Task 5.1: 建立 Docker 生產環境配置

**Files:**
- Modify: `backend/Dockerfile`
- Create: `frontend/Dockerfile`
- Create: `docker-compose.prod.yml`

**Step 1: 更新 backend/Dockerfile**

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim as builder

WORKDIR /app
RUN pip install poetry

COPY pyproject.toml poetry.lock* ./
RUN poetry export -f requirements.txt --output requirements.txt --without-hashes

FROM python:3.11-slim

WORKDIR /app

COPY --from=builder /app/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Step 2: 建立 frontend/Dockerfile**

```dockerfile
# frontend/Dockerfile
FROM node:20-alpine AS builder

WORKDIR /app
RUN corepack enable && corepack prepare pnpm@latest --activate

COPY package.json pnpm-lock.yaml* ./
RUN pnpm install --frozen-lockfile

COPY . .
RUN pnpm build

FROM node:20-alpine AS runner

WORKDIR /app
ENV NODE_ENV=production

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000
ENV PORT 3000

CMD ["node", "server.js"]
```

**Step 3: 更新 frontend/next.config.js**

```javascript
// frontend/next.config.js
/** @type {import('next').NextConfig} */
const nextConfig = {
  output: "standalone",
};

module.exports = nextConfig;
```

**Step 4: 建立 docker-compose.prod.yml**

```yaml
# docker-compose.prod.yml
version: "3.8"

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data:ro
    environment:
      - DATABASE_URL=sqlite:///./data/auspicious.db

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000
    depends_on:
      - backend
```

**Step 5: 測試生產環境建構**

```bash
docker-compose -f docker-compose.prod.yml build
docker-compose -f docker-compose.prod.yml up
# 瀏覽 http://localhost:3000 確認運作正常
docker-compose -f docker-compose.prod.yml down
```

**Step 6: Commit**

```bash
git add -A
git commit -m "feat: add production Docker configuration"
```

---

### Task 5.2: 建立 GitHub Actions CI/CD

**Files:**
- Create: `.github/workflows/ci.yml`

**Step 1: 建立 CI workflow**

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test-backend:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./backend

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Poetry
        run: pip install poetry

      - name: Install dependencies
        run: poetry install

      - name: Run linting
        run: poetry run ruff check .

      - name: Run tests
        run: poetry run pytest -v

  test-frontend:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./frontend

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8

      - name: Install dependencies
        run: pnpm install

      - name: Run linting
        run: pnpm lint

      - name: Build
        run: pnpm build

  docker-build:
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]

    steps:
      - uses: actions/checkout@v4

      - name: Build Docker images
        run: docker-compose -f docker-compose.prod.yml build
```

**Step 2: Commit**

```bash
git add -A
git commit -m "ci: add GitHub Actions workflow"
```

---

## 完成清單

完成以上所有任務後，你將擁有：

- [x] Monorepo 專案結構（backend + frontend + data-pipeline）
- [x] Python 後端環境（Poetry + FastAPI）
- [x] Next.js 前端環境（pnpm + Tailwind + TypeScript）
- [x] 數據下載腳本（從 GitHub 下載台北站 35 年數據）
- [x] 數據清洗模組（處理缺失值、異常值）
- [x] SQLite 資料庫（原始數據 + 統計快照）
- [x] 統計分析引擎（溫度、降水、天氣傾向計算）
- [x] 366 天統計快照預計算
- [x] RESTful API（/weather/daily、/weather/today、/stations）
- [x] 前端首頁（WeatherCard 組件展示今日統計）
- [x] Docker 生產環境配置
- [x] GitHub Actions CI/CD

---

**Plan complete and saved to `docs/plans/2026-02-04-phase1-mvp.md`.**

**Two execution options:**

1. **Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

2. **Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

**Which approach?**
